# Sorting algorithms and their complexities

## Merge sort (сортировка слиянием)
### Принцип работы алгоритма
Алгоритм **merge sort** использует принцип «разделяй и властвуй», процедура сортировки описывается следующим образом:
1. Если в рассматриваемом массиве один элемент, то он уже отсортирован — алгоритм завершает работу
2. Иначе массив разбивается на две части, которые сортируются рекурсивно
3. После сортировки двух частей массива к ним применяется **процедура слияния**, которая по двум отсортированным частям получает исходный отсортированный массив

### Процедура слияния (merge)
Пусть имеем два массива **arr1** (размер n) и **arr2** (размер m) и нам нужно получить массив с размером **n+m**, для этого используем процедуру слияния.
#### Шаги процедуры слияния
1. Создаём новый массив **result** с размером **n+m**
2. Берём первый элемент из первого массива и первый элемент из второго массива и сравниваем их
3. 
	- Если число из первого массива **меньше** ($<$) числа из второго массива, то число из первого массива записываем в **result**
	- Если число из первого массива **больше или равно** ($\geq$) числа из второго массива, то число из второго массива записываем в **result**
4. После записи меньшего элемента **переходим к следующему элементу** в том массиве, откуда взяли число. В другом массиве остаёмся на месте.
5. Повторяем процесс, пока один из массивов полностью не закончится
6. Если в одном из массивов **остались элементы**, просто дописываем их в **result**

Заметим, что при применении **процедуры слияния (merge)**
- Сложность количества действий  равна **$O(n+m)$**
- Сложность использования дополнительной памяти равна **$O(n+m)$**

> Стоит четко отличать функцию `merge` от функции `mergeSort`
>
> `mergeSort` - Получает 1 массив (возможно не отсортированный) и сортирует его
> 
> `merge` - Получает 2 отсортированных массива и получает из них 1 сортированный массив.
>
> `mergeSort` использует `merge`
#### Рассмотрим псевдокод процедуры слияния (merge)
```cpp
vector merge(arr1, arr2)
{
    result = empty vector // массив размера n+m
    it1 = 0, it2 = 0 // индексы начала для первого и второго массива

    while it1 < size(arr1) && it2 < size(arr2)
    {
        if arr1[it1] < arr2[it2] 
            result.push_back(arr1[it1++])
        else
            result.push_back(arr2[it2++])
	}

    // заполняем остальные элементы
    while it1 < size(arr1)
        result.push_back(arr1[it1++])

    while it2 < size(arr2)
        result.push_back(arr2[it2++])

    return result
}
```

#### Теперь рассмотрим псевдокод рекурсивного алгоритма Merge sort
```cpp
vector mergeSort(arr) {
    if size(arr) <= 1 // базовый случай
        return arr

    mid = size(arr) / 2
    left = mergeSort(arr[0:mid]) // левая часть
    right = mergeSort(arr[mid:end]) // правая часть

    return merge(left, right)
}

```

### Визуальное представление merge sort

При передаче функции `mergeSort` массива размера `n` сперва проводятся декствия

```cpp
    if size(arr) <= 1 // базовый случай
        return arr

    mid = size(arr) / 2
```
После чего происходит первый рекурсивный вызов

```cpp
    left = mergeSort(arr[0:mid]) // левая часть
```
То есть вызывается `mergeSort(arr[0:n/2])` и то же самое происходит рекурсивно пока условие `size(arr) <= 1` не станет справедливым. Ниже приведена демонстрация этого:

<p align="center">
  <img src="https://raw.githubusercontent.com/Alohack/algorithms-course/refs/heads/main/Images/mergeSortInDepth1.jpg" width="60%" />
</p>

Заметим, что в данный момент никакие 2 элемента небыли изменены местами, в массиве `arr` ничего не поменялось.

Как можно видеть, если условие `size(arr) <= 1` было справедливым, то происходит `return`, а возврат происходит на ту строку, откуда была вызвана функция

```cpp
    left = mergeSort(arr[0:mid])
```
после этого сработает строка
```cpp
    right = mergeSort(arr[mid:end]) // правая часть
```
То есть вызовется `mergeSort(arr[1:2]) `
<p align="center">
  <img src="https://raw.githubusercontent.com/Alohack/algorithms-course/refs/heads/main/Images/mergeSortInDepth2.jpg" width="60%" />
</p>

После чего опять же происходит `return` туда, откуда была вызвана функция
```cpp
    right = mergeSort(arr[mid:end]) // правая часть
```
И только после этого произойдет merge и сработает строка

```cpp
    return merge(left, right)
```

то есть будет вызвана функция `merge(arr[0:1], merge[1:2])` и функция вернет результат слияния двух массивов размера 1. То есть будут отсортированы первые 2 элемента в массиве
<p align="center">
  <img src="https://raw.githubusercontent.com/Alohack/algorithms-course/refs/heads/main/Images/mergeSortInDepth3.jpg" width="60%" />
</p>

### Примеры

1. Пример работы mergeSort в виде анимации
<p align="center">
  <img src="https://willrosenbaum.com/assets/img/2022f-cosc-311/merge-sort.gif" />
</p>

2. Пример работы mergeSort в случае, когда размер массива не является степенью двойки
<p align="center">
  <img src="https://favtutor.com/resources/images/uploads/mceu_9916660651687944916761.png" />
</p>

3. Еще один пример в виде анимации (кликните, чтобы перейти по ссылке)

[![Video Title](https://i.ytimg.com/vi/ZRPoEKHXTJg/maxresdefault.jpg)](https://youtu.be/ZRPoEKHXTJg?si=QP6TaqoQJPj5lozJ)



### Время работы алгоритма
Чтобы оценить время работы этого алгоритма, составим рекуррентное соотношение, пусть **$T(n)$ - время сортировки массива длины n**.

Чтобы отсортировать массив длины $n$ алгоритм сперва сортирует 2 половины этого массива по отдельности, тратя на каждую из них по $T(\frac{n}{2})$ времени, а далее тратит $O(n)$ шагов на слияния результатов.

Тогда для **merge sort** справедливо равенство
$$T(n) = 2\cdot T(\frac n2) + O(n)$$
$O(n)$ - время, необходимое на то, чтобы слить два массива длины n

Распишем это соотношение:

$$T(n) = 2\cdot T(\frac {n}{2^1}) + O(n)$$
$$T(\frac {n}{2^1}) = 2\cdot T(\frac {n}{2^2}) + O(\frac {n}{2^1})$$
$$T(\frac {n}{2^2}) = 2\cdot T(\frac {n}{2^3}) + O(\frac {n}{2^2})$$
$$\vdots$$
$$T(\frac {n}{2^k}) = 1$$

Получили:

$$\frac {n}{2^k} \leq 1$$
$$2^k \geq n$$
$$k \geq \log_2n$$
А наименьшее целое число, которое больше либо равно $log_2 n$ равно
$$k = \lceil\log_2n\rceil$$

Умножим каждую часть соотношения на соответствующую степень 2, получим:

$$2^0\cdot T(n) = 2^1\cdot T(\frac {n}{2^1}) + O(n)$$
$$2^1\cdot T(\frac {n}{2^1}) = 2^2\cdot T(\frac {n}{2^2}) + O(n)$$
$$2^2\cdot T(\frac {n}{2^2}) = 2^3\cdot T(\frac {n}{2^3}) + O(n)$$
$$\vdots$$
$$2^k\cdot T(\frac {n}{2^k}) = 2^k \leq 2n$$

Сложим все эти равенства, получим:

$$T(n) \leq n \cdot(k+2) = n \cdot (\lceil\log_2n\rceil + 2) = O(n\log n)$$
$O(n\log n)$ $-$ сложность количества действий алгоритма **merge sort**, такую сложность называют линейно-логарифмической (это не только верхняя граница, но и нижняя)


Вопрос читателю: Можно ли оптимизировать данный код, чтобы программа занимала бы меньше памяти?

## Quick sort (быстрая сортировка)
### Принцип работы алгоритма
Алгоритм **quick sort** также использует принцип «разделяй и властвуй», процедура сортировки описывается следующим образом:
1. Если в рассматриваемом массиве один элемент, то он уже отсортирован — алгоритм завершает работу
2. Иначе выбираем **опорный элемент** (pivot)
3. Разделяем массив на две части используя **процедуру разбиения** (partition):
	- первый массив состоит из всех элементов **меньше опорного элемента** (pivot)
	- второй массив состоит из всех элементов **больше или равно опорного элемента** (pivot)
4. Рекурсивно сортируем обе части
5. Объединяем результаты
### Процедура разбиения (partition)
Предположим, у нас есть массив **a[l…r]** (**l** — индекс левого конца массива, **r** — индекс правого конца массива). Процедура разбиения изменяет расположение элементов в массиве так, что элементы слева от некоторого **опорного элемента** (pivot) меньше или равны этому значению, а элементы справа — больше или равны ему.
#### Шаги процедуры разбиения
1. Выбираем **опорный элемент** (pivot), в нашем случае будем выбирать `arr[(l + r) / 2]`
2. Используем два индекса:
	- **i** индекс левого конца массива (изначально **l**)
	- **j** индекс правого конца массива (изначально **r**)
3. Пока **i** $\leq$ **j**
	- Двигаем **i** вправо, пока не найдём элемент, который **больше или равно опорному элемента** (pivot)
	- Двигаем **j** влево, пока не найдём элемент, который **меньше или равно опорному элементу** (pivot)
	- Если **i** и **j** ещё не пересеклись, меняем местами (swap) найденные элементы
4. Как только индексы **i** и **j** пересекаются, процедура заканчивается.
#### Рассмотрим псевдокод процедуры разбиения (partition)
```cpp
int partition(arr) {

    v = arr[(l + r) / 2] // выбираем разделяющий элемент
    i = l, j = r // индексы для левого и правого конца массива

    while i <= j {
        // перемещаем левый индекс вправо, пока элемент меньше разделяющего
        while arr[i] < v 
            i++
        
        // перемещаем правый индекс влево, пока элемент больше разделяющего
        while arr[j] > v 
            j--
        
        // если индексы не пересеклись, меняем элементы местами
        if i <= j {
            swap(arr[i], arr[j]) 
            i++
            j--
        }
    }

    return j // возвращаем индекс разделяющего элемента
}

```
#### Теперь рассмотрим псевдокод рекурсивного алгоритма quick sort
```cpp
void quicksort(a, l, r) {
    // Базовый случай: если подмассив содержит один или менее элементов, он уже отсортирован
    if l < r {
        // вызываем функцию partition, чтобы найти индекс разделяющего элемента
        q = partition(a, l, r)
        
        // рекурсивно сортируем левую часть массива
        quicksort(a, l, q)
        
        // рекурсивно сортируем правую часть массива
        quicksort(a, q + 1, r)
    }
}
```
### Время работы алгоритма
#### Худшее время работы
Рассмотрим случай, когда разбиение массива происходит неравномерно: одна часть содержит **$n−1$** элементов, а другая — **$1$**
Так как процедура разбиения выполняется за **$Θ(n)$**, для времени работы **$T(n)$** получаем рекуррентное соотношение:
$$T(n) = T(n-1) + O(n) = \sum_{k=1}^n Θ(k) = Θ(\sum_{k=1}^nk) = Θ(n^2)$$
Такой случай возникает, если **опорный элемент** (pivot) каждый раз после **процедуры разбиения** (partition) оказывается либо в начале, либо в конце массива, что делает разбиение неэффективным.
#### Среднее время работы
Среднее время работы алгоритма **quick sort** равно $O(n\log n)$, такой сложности мы достигаем, если **опорный элемент** (pivot) падает на середину (или почти середину) массива.
### Сравнение с bubble sort
Рассмотрим таблицу:

|  Алгоритм   | Сложность в лучшем случае | Сложность в худшем случае |
|:-----------:|:-------------------------:|:-------------------------:|
| Quick sort  |       **$n\log n$**       |         **$n^2$**         |
| Bubble sort |          **$n$**          |         **$n^2$**         |

По данной таблице можно подумать, что bubble sort лучше quick sort, но у quick sort в среднем худший случай случается реже

### Амортизированная сложность
Quick sort амортизированно работает за **$O(n \log n)$**
Bubble sort амортизированно работает за **$O(n^2)$**

Таким образом приходим к следующей таблице
|  Алгоритм   | Сложность в лучшем случае | Сложность в худшем случае |Амортизированная сложность |
|:-----------:|:-------------------------:|:-------------------------:|:-------------------------:|
| Merge sort  |       **$n\log n$**       |       **$n\log n$**       |         **$n\log n$**     |
| Quick sort  |       **$n\log n$**       |         **$n^2$**         |         **$n\log n$**     |
| Bubble sort |          **$n$**          |         **$n^2$**         |         **$n^2$**         |

### Визуальное представление quick sort
#### Общее представление
![[Drawing 2025-02-06 19.25.29.excalidraw|600x600]]
#### Пример
![[Quicksort.png]]
### Код quick sort
```cpp
#include <algorithm>
#include <vector>

// Функция для разделения массива
int partition(std::vector<int>& arr, int low, int high) {
    int pivot = arr[high];
    int i = low - 1;

    for (int j = low; j < high; j++) {
        if (arr[j] < pivot) {
            i++;
            std::swap(arr[i], arr[j]);
        }
    }
    std::swap(arr[i + 1], arr[high]);
    return i + 1;
}

// Рекурсивная функция для быстрой сортировки
void quicksort(std::vector<int>& arr, int low, int high) {
    if (low < high) {
        int pi = partition(arr, low, high);
        quicksort(arr, low, pi - 1);
        quicksort(arr, pi + 1, high);
    }
}
```
## Heap sort (сортировка кучей)
### Принцип работы алгоритма
Алгоритм **Heap Sort** работает через структуру данных **куча** и использует принцип **сортировки выбором**. 
Мы будем использовать кучу для того, чтобы в процессе сортировки на каждом шаге извлекать наибольший элемент и ставить его на своё место в отсортированной части массива, процедура сортировки описывается следующим образом:
1. Строим из массива кучу с помощью **make_heap** (сложность $O(n)$)
2. Пока куча не станет пустой делаем **pop_heap** (сложность $O(\log n)$)
#### Псевдокод
Рассмотрим псевдокод **heap sort**
```cpp
#include <algorithm> // Для make_heap и pop_heap

void heapSort(arr) {
    int heapSize = arr.size();

    // Строим кучу
    make_heap(arr);

    // Процесс сортировки
    for (int i = 0; i < arr.size() - 1; ++i) {
        // Меняем корень с последним элементом
        swap(arr[0], arr[heapSize - 1 - i]);

        // Уменьшаем размер кучи с помощью pop_heap
        pop_heap(A.begin(), A.begin() + heapSize - i);

        // Куча обновляется, но элементы отсортированы на своих местах
    }
}
```
### Время работы алгоритма
- Совместив эти две операции в итоге получаем общую сложность алгоритма **$O(n\log n)$**
- Сложность использования дополнительной памяти **$O(1)$**
Заметим, недостаток **heap sort**:
На почти отсортированных данных данный алгоритм работает столь же долго, как на несортированных
### Визуальное представление heap sort
![[heapsort.png]]
### Код heap sort
```cpp
#include <vector>
#include <algorithm>

// Функция для построения кучи и сортировки
void heapsort(std::vector<int>& arr) {
    // Преобразуем массив в кучу
    std::make_heap(arr.begin(), arr.end());

    // Извлекаем элементы из кучи и сортируем
    for (auto i = arr.end(); i != arr.begin(); --i) {
        std::pop_heap(arr.begin(), i);
    }
}
```
# Lower bound for comparison based sorting with the proof
## Сортировка сравнениями
**Сортировка сравнениями** $-$ алгоритм сортировки, который совершает операции сравнения элементов, но никак не использует их внутреннюю структуру.
## Теорема (о нижней оценке для сортировки сравнениями):
В худшем случае любой алгоритм сортировки сравнениями выполняет $\Omega(n\log n)$ действий, где $n$ $-$ число сортируемых элементов.
### Доказательство:
Любой алгоритм сортировки сравнениями можно представить в виде **дерева выбора**:

![[Drawing 2025-02-06 18.01.12.excalidraw|400x400]]

Пример:
Пусть имеем массив с элементами $({a[0],a[1],a[2]})$, нарисуем для него **плохое дерево выбора**
![[Drawing 2025-02-06 18.13.12.excalidraw|500x500]]
При сравнении элементов заметим, что возможно два исхода, значит, у каждого узла есть не более двух сыновей, всего существует **$n!$** различных перестановок **$n$** элементов, значит, число листьев дерева не менее $n!$

Красным цветом отмечена часть, которая не имеет смысла (делает дерево выбора плохим)
Заметим, что в дереве выбора, количество сравнений в худшем случае может быть равна высоте дерева

#### Утверждение:
Если в бинарном дереве **$L$** листьев, то **$L \leq 2^h$**
##### Доказательство:
Докажем методом математической индукции:
Пусть **$h=0$**, тогда получим **$1 \leq 2^0$** и **$0 \leq 2^0$**
Предположим, что неравенство верно для **$h$**
Докажем для **$h+1$**:
![[Drawing 2025-02-06 18.43.10.excalidraw]]
Если у нашего узла два поддерева и наша общая высота равна **$h+1$**, то мы точно можем сказать, что высота одного из поддеревьев равна **$h$**, а высота другого **$\leq h$**
Допустим в нашем случае 
- Высота левого поддерева **$h_1 = h$**
- Высота правого поддерева **$h_2 \leq h$**
То есть высота дерева не больше, чем **$2 \cdot 2^h = 2^{h+1}$**
Получили неравенство **$L \leq 2^{h+1}$** $\implies$ доказали, что **$L \leq 2^h$**

Из данного утверждения следует, что $$n! \leq 2^h$$ $$h \geq \log_2 n! = \log_2 (1 \cdot 2 \cdot 3 \dotso \cdot [\frac n2] \cdot ([\frac n2] + 1) \cdot \dotso \cdot n) \geq \log_2 (\frac n2)^\frac n2 = \frac n2 \log_2 \frac n2 = \Omega(n\log n)$$
В итоге доказали, что никакой алгоритм сортировки сравнениями в худшем случае не может быть быстрее **$O(n\log n)$**